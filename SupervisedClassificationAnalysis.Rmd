---
title: "firstAnalysis"
author: "Jean-Francois Chartier"
date: "17 janvier 2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



#install packages
```{r}

if ("magrittr" %in% installed.packages()==FALSE){
  install.packages('quanteda',dependencies = TRUE)
}
library(magrittr)

if ("caret" %in% installed.packages()==FALSE){
  install.packages('caret',dependencies = TRUE)
}
library(caret)
if ("rpart" %in% installed.packages()==FALSE){
  install.packages('rpart',dependencies = TRUE)
}
library(rpart)

if ("quanteda" %in% installed.packages()==FALSE){
  install.packages('quanteda',dependencies = TRUE)
}
library(quanteda)

```

```{r}
#function to create a unit normed vector
normVector <- function(x) 
{
  if(sum(x)==0)
    return (x)
  else 
    return (x / sqrt(sum(x^2)))
  
}
#function to norm many vectors
normRowVectors<-function(m){
  t(apply(m, MARGIN = 1, FUN = function(x) normVector(x)))
}
```


#read data
```{r}
mood.industry.data=readRDS("mood.industry.data.rds")
wordfrequency.matrix.regcan=readRDS("wordfrequency.matrix.regcan.rds")
#reduced.svd.regcan.doc=readRDS("reduced.svd.regcan.doc.rds")

#svd.of.regcan.from.irba = readRDS("svd.of.regcan.from.irba.150.rds")

#reduced.svd.regcan.doc=  as.matrix(svd.of.regcan.from.irba$u %*% solve(diag((svd.of.regcan.from.irba$d)))) #%>% normRowVectors()
#colnames(reduced.svd.regcan.doc)=svd.of.regcan.from.irba$feature.names

ngramfrequency.matrix.regcan=readRDS("ngramfrequency.matrix.regcan.rds")

reduced.matrix.context.rias=readRDS("reduced.matrix.context.rias.rds")

sentiment.regcan.matrix=readRDS("sentiment.regcan.matrix.rds")
```

#read all latent models
```{r}
n.latents=c(50, 100, 150, 200, 300, 400, 500, 800)

latent.models=lapply(n.latents, FUN = function(k){
  svd.of.regcan.from.irba = readRDS(paste0("svd.of.regcan.from.irba.", k, ".rds"))
  
  reduced.svd.regcan.doc=  as.matrix(svd.of.regcan.from.irba$u %*% solve(diag((svd.of.regcan.from.irba$d)))) #%>% normRowVectors()
  colnames(reduced.svd.regcan.doc)=paste0(k,".",svd.of.regcan.from.irba$feature.names)
  reduced.svd.regcan.doc
  })

```


#get training id
```{r}

id.train=mood.industry.data$training.set==T
```

#Combine features
##add meta data
```{r}
data.classification=mood.industry.data[,c(3:6,8)]
```

##add word-matrix frequency
```{r}
data.classification=cbind(data.classification, as.matrix(wordfrequency.matrix.regcan)%>%set_colnames(., wordfrequency.matrix.regcan@Dimnames$features))
```

##add n-gram
```{r}
data.classification=cbind(data.classification, as.matrix(ngramfrequency.matrix.regcan)%>%set_colnames(., ngramfrequency.matrix.regcan@Dimnames$features))
```

##add sentiment features
```{r}
data.classification=cbind(data.classification, sentiment.regcan.matrix)
```

##add all latent models
```{r}
all.latent.models=do.call("cbind", latent.models)
data.classification=cbind(data.classification, all.latent.models)
```

##add global.rias.latent
```{r}
#add global.rias.latent
data.classification=cbind(data.classification, reduced.matrix.context.rias)

```


#prepare data for ml
```{r}

#change NA in sponsor
#data.classification=data.classification.train
i=data.classification$sponsor.feature%>%is.na(.)
data.classification$sponsor.feature=as.character(data.classification$sponsor.feature)
data.classification$sponsor.feature[i]="unknown.sponsor"
data.classification$sponsor.feature=as.factor(data.classification$sponsor.feature)

#extract train and test sets
data.classification.train=data.classification[id.train, ]
data.classification.test=data.classification[id.train==F, ]

```


#prepare classification labels
```{r}
negative.class=(data.classification$label_of_class=="no_comment" | data.classification$label_of_class=="no_consultation" |  data.classification$label_of_class=="no_statement")

binary.label=character(length = length(negative.class))
binary.label[negative.class]="is.not.consultation.label"
binary.label[negative.class==F]="is.consultation.label"

multi.class.label=data.classification$label_of_class

```

#Learn binary class model
##set label
```{r}
#set label to binary class
data.classification.train$label_of_class=as.factor(binary.label[id.train])
```

##learn Random Forest on subset of training set
```{r}
seed=123

#id.sub.train
id.sub.train <- sample(nrow(data.classification.train), 3/4 * nrow(data.classification.train))


rf.model=ranger::ranger(dependent.variable.name = "label_of_class", data=data.classification.train[id.sub.train,], num.trees=10000, num.threads=6, classification=T, importance="impurity")

#View(rf.model$variable.importance)

rf.pred=predict(rf.model, data = data.classification.train[-id.sub.train,])

eval<-caret::confusionMatrix(data=rf.pred$predictions, reference=as.factor(data.classification.train$label_of_class[-id.sub.train]), mode="everything")
eval

```

##learn class likelihood over  training set
```{r}

rf.model=ranger::ranger(dependent.variable.name = "label_of_class", data=data.classification.train, num.trees=10000, num.threads=6, probability=T, classification=T)

```

##Predict binary class on test set
```{r}
#do not used column 4. It is the label
rf.binary.label.prediction=predict(rf.model, data = data.classification.test[,(-4)])


```

#Learn multiple classes model
##set label
```{r}
#set label to multi class
data.classification.train$label_of_class=as.factor(multi.class.label[id.train])
```
##learn Random Forest on subset of training set

```{r}
seed=123

#subset of id train
id.sub.train <- sample(nrow(data.classification.train), 3/4 * nrow(data.classification.train))


rf.multiclasses.model=ranger::ranger(dependent.variable.name = "label_of_class", data=data.classification.train[id.sub.train,], num.trees=10000, num.threads=6, classification=T, importance="impurity")

#View(rf.model$variable.importance)

rf.multiclasses.pred=predict(rf.multiclasses.model, data = data.classification.train[-id.sub.train,])

eval<-caret::confusionMatrix(data=rf.multiclasses.pred$predictions, reference=as.factor(data.classification.train$label_of_class[-id.sub.train]), mode="everything")
eval

```

##learn class likelihood over  training set
```{r}

rf.multiclasses.model=ranger::ranger(dependent.variable.name = "label_of_class", data=data.classification.train, num.trees=10000, num.threads=6, probability=T, classification=T)

```

##Predict binary class on test set
```{r}
#do not used column 4. It is the label
rf.multiclasses.label.prediction=predict(rf.multiclasses.model, data = data.classification.test[,(-4)])


```

#Learn multiple classes model with one negative class
##set label
```{r}
#set label to multi class
data.classification.train$label_of_class=(multi.class.label[id.train])%>%as.character(.)

data.classification.train$label_of_class[binary.label[id.train]=="is.not.consultation.label"]=binary.label[id.train]%>%extract(.=="is.not.consultation.label")

data.classification.train$label_of_class=data.classification.train$label_of_class%>%as.factor(.)%>%droplevels(.)
```
##learn Random Forest on subset of training set

```{r}
seed=123

#subset of id train
id.sub.train <- sample(nrow(data.classification.train), 2/3 * nrow(data.classification.train))

#upSampledTrain <- upSample(x = data.classification.train[id.sub.train, -c(4)], y = data.classification.train[id.sub.train,]$label_of_class, yname = "label_of_class")

rf.multiclasses.model=ranger::ranger(dependent.variable.name = "label_of_class", data=data.classification.train[id.sub.train,], num.trees=20000, num.threads=6, classification=T, importance = "impurity")

#use for stratified sampling https://github.com/imbs-hl/ranger/issues/381
#sample.fraction=c(0.5,.5,.5,.5,.5,.5,.5)

#rf.multiclasses.model=ranger::ranger(dependent.variable.name = "label_of_class", data=data.classification.train[id.sub.train,], num.trees=0000, num.threads=6, classification=T, importance="impurity", class.weights=c(1,1,1,1,1,1,1))

View(rf.multiclasses.model$variable.importance)

rf.multiclasses.pred=predict(rf.multiclasses.model, data = data.classification.train[-id.sub.train,])

eval<-caret::confusionMatrix(data=rf.multiclasses.pred$predictions, reference=as.factor(data.classification.train$label_of_class[-id.sub.train]), mode="everything")
eval
View(eval$byClass)
```

##learn class likelihood over  training set
```{r}

rf.multiclasses.model=ranger::ranger(dependent.variable.name = "label_of_class", data=data.classification.train, num.trees=10000, num.threads=6, probability=T, classification=T)

```

##Predict binary class on test set
```{r}
#do not used column 4. It is the label
rf.multiclasses.label.prediction=predict(rf.multiclasses.model, data = data.classification.test[,(-4)])


```


#Learn hierarchical random forest

##learn Random Forest on 2/3 of training set

```{r}
seed=123
#set label to binary class
data.classification.train$label_of_class=as.factor(binary.label[id.train])

#subset of id train
id.sub.train <- sample(nrow(data.classification.train), 2/3 * nrow(data.classification.train))


rf.bin.model=ranger::ranger(dependent.variable.name = "label_of_class", data=data.classification.train[id.sub.train,], num.trees=40000, num.threads=6, classification=T, importance = "impurity")

View(rf.bin.model$variable.importance, title = "impurity over binary classes")

#get exemplars from the "is.consultation.label" class
id.sub.is.consultation=data.classification.train$label_of_class[id.sub.train]=="is.consultation.label"
#set label to multi class
data.classification.train$label_of_class=as.factor(multi.class.label[id.train])

data.classification.train.consul=data.classification.train[id.sub.train,][id.sub.is.consultation,]%>%droplevels(.)

#subset of id train
#id.sub.train.consul <- sample(nrow(data.classification.train.consul), 3/4 * nrow(data.classification.train.consul))



#learn model of multiclassification only on consultation exemplars
rf.multi.model.consul=ranger::ranger(dependent.variable.name = "label_of_class", data=data.classification.train.consul, num.trees=30000, num.threads=6, classification=T, importance = "impurity")

View(rf.multi.model.consul$variable.importance, title = "impurity over multi classes")

```

##Predict with hierarchical random forest on 1/3 of training set
```{r}
rf.bin.pred=predict(rf.bin.model, data = data.classification.train[-id.sub.train,])

rf.multi.pred=predict(rf.multi.model.consul, data=data.classification.train[-id.sub.train,][rf.bin.pred$predictions=="is.consultation.label",])

#join predictions
rf.joint.pred=rf.bin.pred$predictions%>%as.character(.)
rf.joint.pred[rf.joint.pred=="is.consultation.label"]=rf.multi.pred$predictions%>%as.character(.)

my.reference=multi.class.label[id.train][-id.sub.train]%>%as.character()
my.reference[binary.label[id.train][-id.sub.train]=="is.not.consultation.label"]=binary.label[id.train][-id.sub.train]%>%extract(.=="is.not.consultation.label")

eval<-caret::confusionMatrix(data=as.factor(rf.joint.pred), reference=as.factor(my.reference), mode="everything")
eval
View(eval$byClass)
#write.csv(eval$byClass, file = "evalRFhierarchic.csv", row.names = T, col.names = T, fileEncoding = "utf8")
```


##Learn over all training set 
```{r}
seed=123
#set label to binary class
data.classification.train$label_of_class=as.factor(binary.label[id.train])


rf.bin.model=ranger::ranger(dependent.variable.name = "label_of_class", data=data.classification.train, num.trees=50000, num.threads=6, classification=T, importance = "impurity", probability=T)

View(rf.bin.model$variable.importance, title = "impurity over binary classes")

#get exemplars from the "is.consultation.label" class
id.sub.is.consultation=data.classification.train$label_of_class=="is.consultation.label"
#set label to multi class
data.classification.train$label_of_class=as.factor(multi.class.label[id.train])

data.classification.train.consul=data.classification.train[id.sub.is.consultation,]%>%droplevels(.)

#learn model of multiclassification only on consultation exemplars
rf.multi.model.consul=ranger::ranger(dependent.variable.name = "label_of_class", data=data.classification.train.consul, num.trees=50000, num.threads=6, classification=T, importance = "impurity", probability = T)

View(rf.multi.model.consul$variable.importance, title = "impurity over multi classes")
```

##Predict with hierarchical random forest on test set
```{r}
rf.bin.pred=predict(rf.bin.model, data = data.classification.test[,(-4)])

rf.multi.pred=predict(rf.multi.model.consul, data=data.classification.test[rf.bin.pred$predictions[,1]>.5, (-4)])

#join predictions
rf.joint.pred=rf.bin.pred$predictions
multi.class.pred=rep(NA, times=nrow(rf.joint.pred))
multi.class.pred=cbind(multi.class.pred,multi.class.pred,multi.class.pred) %>%set_colnames(., colnames(rf.multi.pred$predictions))
multi.class.pred[rf.bin.pred$predictions[,1]>.5,]=rf.multi.pred$predictions
rf.joint.pred=cbind(rf.joint.pred, multi.class.pred)

```

##save class prediction
```{r}
prediction.on.test.set=cbind(mood.industry.data[id.train==F, ], (rf.joint.pred))
saveRDS(prediction.on.test.set, "hierar.RF.prediction.on.test.set.rds")
write.table(prediction.on.test.set, file="hierar.RF.prediction.on.test.set.csv", col.names = T, fileEncoding = "utf8", quote=T, sep=",")
```


```{r}
prediction.on.test.set=readRDS("hierar.RF.prediction.on.test.set.rds")
write.csv2(prediction.on.test.set, file="hierar.RF.prediction.on.test.set.csv", col.names = T, fileEncoding = "utf8", quote=T, sep=";")
```



#END
