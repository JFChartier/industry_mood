---
title: "RegressionAnalysisOfAnnotationProb"
author: "Jean-Francois Chartier"
date: "22 mars 2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#install packages
```{r}

if ("magrittr" %in% installed.packages()==FALSE){
  install.packages('quanteda',dependencies = TRUE)
}
library(magrittr)

if ("caret" %in% installed.packages()==FALSE){
  install.packages('caret',dependencies = TRUE)
}
library(caret)
if ("rpart" %in% installed.packages()==FALSE){
  install.packages('rpart',dependencies = TRUE)
}
library(rpart)

if ("quanteda" %in% installed.packages()==FALSE){
  install.packages('quanteda',dependencies = TRUE)
}
library(quanteda)

```


```{r}
#function to create a unit normed vector
normVector <- function(x) 
{
  if(sum(x)==0)
    return (x)
  else 
    return (x / sqrt(sum(x^2)))
  
}
#function to norm many vectors
normRowVectors<-function(m){
  t(apply(m, MARGIN = 1, FUN = function(x) normVector(x)))
}
```


#read data
```{r}
mood.industry.data=readRDS("mood.industry.data.with.prob.rds")
wordfrequency.matrix.regcan=readRDS("wordfrequency.matrix.regcan.rds")
#reduced.svd.regcan.doc=readRDS("reduced.svd.regcan.doc.rds")

#svd.of.regcan.from.irba = readRDS("svd.of.regcan.from.irba.150.rds")

#reduced.svd.regcan.doc=  as.matrix(svd.of.regcan.from.irba$u %*% solve(diag((svd.of.regcan.from.irba$d)))) #%>% normRowVectors()
#colnames(reduced.svd.regcan.doc)=svd.of.regcan.from.irba$feature.names

ngramfrequency.matrix.regcan=readRDS("ngramfrequency.matrix.regcan.rds")

reduced.matrix.context.rias=readRDS("reduced.matrix.context.rias.rds")

sentiment.regcan.matrix=readRDS("sentiment.regcan.matrix.rds")
```

#read all latent models
```{r}
n.latents=c(50, 100, 150, 200, 300, 400, 500, 800)

latent.models=lapply(n.latents, FUN = function(k){
  svd.of.regcan.from.irba = readRDS(paste0("svd.of.regcan.from.irba.", k, ".rds"))
  
  reduced.svd.regcan.doc=  as.matrix(svd.of.regcan.from.irba$u %*% solve(diag((svd.of.regcan.from.irba$d)))) #%>% normRowVectors()
  colnames(reduced.svd.regcan.doc)=paste0(k,".",svd.of.regcan.from.irba$feature.names)
  reduced.svd.regcan.doc
  })

```


#get training id
```{r}

id.train=mood.industry.data$training.set==T
```

#Combine features
##add meta data
```{r}
data.classification=mood.industry.data[,c(3:5,8, 10:13)]
```

##add word-matrix frequency
```{r}
data.classification=cbind(data.classification, as.matrix(wordfrequency.matrix.regcan)%>%set_colnames(., wordfrequency.matrix.regcan@Dimnames$features))
```

##add n-gram
```{r}
data.classification=cbind(data.classification, as.matrix(ngramfrequency.matrix.regcan)%>%set_colnames(., ngramfrequency.matrix.regcan@Dimnames$features))
```

##add sentiment features
```{r}
data.classification=cbind(data.classification, sentiment.regcan.matrix)
```

##add all latent models
```{r}
all.latent.models=do.call("cbind", latent.models)
data.classification=cbind(data.classification, all.latent.models)
```

##add global.rias.latent
```{r}
#add global.rias.latent
data.classification=cbind(data.classification, reduced.matrix.context.rias)

```

#prepare data for ml
```{r}

#change NA in sponsor
#data.classification=data.classification.train
i=data.classification$sponsor.feature%>%is.na(.)
data.classification$sponsor.feature=as.character(data.classification$sponsor.feature)
data.classification$sponsor.feature[i]="unknown.sponsor"
data.classification$sponsor.feature=as.factor(data.classification$sponsor.feature)

#extract train and test sets
data.classification.train=data.classification[id.train, ]
data.classification.test=data.classification[id.train==F, ]

```

#Regression on is.not.consultation 
##train on sub training set
```{r}
seed=123
data.classification.train.not.consultation = data.classification.train[,-c(4,6:8)]
#subset of id train
id.sub.train <- sample(nrow(data.classification.train.not.consultation), 2/3 * nrow(data.classification.train.not.consultation))


rf.bin.model=ranger::ranger(dependent.variable.name = "is.not.consultation.prob", data=data.classification.train.not.consultation[id.sub.train,], num.trees=40000, num.threads=6, classification=F, importance = "impurity")

View(rf.bin.model$variable.importance, title = "impurity over is.not.consultation class")



```

##Predict regression on 1/3 of training set
```{r}
rf.bin.pred=predict(rf.bin.model, data = data.classification.train.not.consultation[-id.sub.train,])

cor(data.classification.train.not.consultation$is.not.consultation.prob[-id.sub.train], rf.bin.pred$predictions)

plot(data.classification.train.not.consultation$is.not.consultation.prob[-id.sub.train], rf.bin.pred$predictions)

```

#Regression on institution label 
##train on sub training set
```{r}
seed=123
data.classification.train.institution = data.classification.train[,-c(4:6,8)]
#subset of id train
id.sub.train <- sample(nrow(data.classification.train.institution), 2/3 * nrow(data.classification.train.institution))


rf.institution.model=ranger::ranger(dependent.variable.name = "statement.institution.prob", data=data.classification.train.institution[id.sub.train,], num.trees=20000, num.threads=6, classification=F, importance = "impurity")

View(rf.institution.model$variable.importance, title = "impurity over is.not.consultation class")

```

##Predict regression on 1/3 of training set
```{r}
rf.institution.pred=predict(rf.institution.model, data = data.classification.train.institution[-id.sub.train,])

cor(data.classification.train.institution$statement.institution.prob[-id.sub.train], rf.institution.pred$predictions)

plot(data.classification.train.institution$statement.institution.prob[-id.sub.train], rf.institution.pred$predictions, xlab = "observations", ylab = "predictions")

```

#Regression on advocacy 
##train on sub training set
```{r}
seed=123
data.classification.train.advocacy = data.classification.train[,-c(4:5,7:8)]
#subset of id train
id.sub.train <- sample(nrow(data.classification.train.advocacy), 2/3 * nrow(data.classification.train.advocacy))


rf.advocacy.model=ranger::ranger(dependent.variable.name = "statement.advocacy.prob", data=data.classification.train.advocacy[id.sub.train,], num.trees=20000, num.threads=6, classification=F, importance = "impurity")

View(rf.institution.model$variable.importance, title = "impurity over is.not.consultation class")

```

##Predict regression on 1/3 of training set
```{r}
rf.advocacy.pred=predict(rf.advocacy.model, data = data.classification.train.advocacy[-id.sub.train,])

cor(data.classification.train.advocacy$statement.advocacy.prob[-id.sub.train], rf.advocacy.pred$predictions)

plot(data.classification.train.advocacy$statement.advocacy.prob[-id.sub.train], rf.advocacy.pred$predictions, xlab = "observations", ylab = "predictions")

```